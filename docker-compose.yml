version: "2.1"

volumes:
  downloads: {}
  duplicati: {}
  jellyfin: {}
  letsencrypt: {}
  netdatalib: {}
  netdatacache: {}
  nzbget: {}
  nzbhydra: {}
  ombi: {}
  overseerr: {}
  plex: {}
  prowlarr: {}
  proxy: {}
  radarr: {}
  sabnzbd: {}
  sonarr: {}
  syncthing: {}
  tailscale: {}
  tautulli: {}

services:
  # https://docs.linuxserver.io/images/docker-plex
  plex:
    image: linuxserver/plex:1.32.5@sha256:59f2095f1bc4ebd4bc5bf07c28ef55082039d42dd5f34806901c24efa893ee1b
    entrypoint: /bin/sh -c "[ -n \"${DISABLE}\" ] || exec /init"
    restart: on-failure
    devices:
      - /dev/dri:/dev/dri
    environment:
      PUID: "1000"
      PGID: "1000"
    ports:
      - 32400:32400/tcp
    tmpfs:
      - /tmp
    volumes:
      - plex:/config
      - downloads:/downloads

  # https://docs.linuxserver.io/images/docker-jellyfin
  jellyfin:
    image: linuxserver/jellyfin:10.8.10@sha256:167fb73634860ef5506b1760838dcdb2870fdb24e3a27b5b53104c54a14e5991
    entrypoint: /bin/sh -c "[ -n \"${DISABLE}\" ] || exec /init"
    restart: on-failure
    devices:
      - /dev/dri:/dev/dri
    environment:
      PUID: "1000"
      PGID: "1000"
    ports:
      - 8096:8096/tcp
      - 7359:7359/udp
    tmpfs:
      - /tmp
    volumes:
      - jellyfin:/config
      - downloads:/downloads

  # https://docs.linuxserver.io/images/docker-nzbget
  nzbget:
    image: linuxserver/nzbget:21.1.20230119@sha256:ed58a6471591126adee01e704d35264979640bede1fca7ffa13a21d6643c5a18
    entrypoint: /bin/sh -c "[ -n \"${DISABLE}\" ] || exec /init"
    restart: on-failure
    environment:
      PUID: "1000"
      PGID: "1000"
    ports:
      - 127.0.0.1:6789:6789/tcp
    tmpfs:
      - /tmp
    volumes:
      - nzbget:/config
      - downloads:/downloads

  # https://docs.linuxserver.io/images/docker-sonarr
  sonarr:
    image: linuxserver/sonarr:3.0.10@sha256:02ec9b37729b478d811aba135af61d8daa8e722c3b878af2b4291c065f414621
    entrypoint: /bin/sh -c "[ -n \"${DISABLE}\" ] || exec /init"
    restart: on-failure
    depends_on:
      - nzbhydra
      - nzbget
      - prowlarr
    environment:
      PUID: "1000"
      PGID: "1000"
    ports:
      - 127.0.0.1:8989:8989/tcp
    tmpfs:
      - /tmp
    volumes:
      - sonarr:/config
      - downloads:/downloads

  # https://docs.linuxserver.io/images/docker-radarr
  radarr:
    image: linuxserver/radarr:4.6.4@sha256:499a88df24de0bedd248366033fe14b6745fde49ef84345ccd759f49d5a3549d
    entrypoint: /bin/sh -c "[ -n \"${DISABLE}\" ] || exec /init"
    restart: on-failure
    depends_on:
      - nzbhydra
      - nzbget
      - prowlarr
    environment:
      PUID: "1000"
      PGID: "1000"
    ports:
      - 127.0.0.1:7878:7878/tcp
    tmpfs:
      - /tmp
    volumes:
      - radarr:/config
      - downloads:/downloads

  # https://docs.linuxserver.io/images/docker-prowlarr
  prowlarr:
    image: linuxserver/prowlarr:1.7.3-develop@sha256:44f89011e9888d4c0d5496cb948283ba38fb80fb05a377f6f121c81e3915f225
    entrypoint: /bin/sh -c "[ -n \"${DISABLE}\" ] || exec /init"
    restart: on-failure
    environment:
      PUID: "1000"
      PGID: "1000"
    ports:
      - 127.0.0.1:9696:9696/tcp
    tmpfs:
      - /tmp
    volumes:
      - prowlarr:/config
      - downloads:/downloads

  # https://docs.linuxserver.io/images/docker-nzbhydra
  nzbhydra:
    image: linuxserver/nzbhydra2:5.1.10@sha256:aeb3bb3c9266b0cd8c6a76c8f2fe631ca4566d3ba324d1d6c93e1a73d7c35529
    entrypoint: /bin/sh -c "[ -n \"${DISABLE}\" ] || exec /init"
    restart: on-failure
    environment:
      PUID: "1000"
      PGID: "1000"
    ports:
      - 127.0.0.1:5076:5076/tcp
    tmpfs:
      - /tmp
    volumes:
      - nzbhydra:/config
      - downloads:/downloads

  # https://docs.linuxserver.io/images/docker-ombi
  ombi:
    image: linuxserver/ombi:4.39.1@sha256:691e110450cec250bc7ace3b8075b81221b2668722745abd339498b8a45cb6fe
    entrypoint: /bin/sh -c "[ -n \"${DISABLE}\" ] || exec /init"
    restart: on-failure
    environment:
      PUID: "1000"
      PGID: "1000"
    ports:
      - 127.0.0.1:3579:3579/tcp
    tmpfs:
      - /tmp
    volumes:
      - ombi:/config

  # https://docs.linuxserver.io/images/docker-overseerr
  overseerr:
    image: lscr.io/linuxserver/overseerr:1.33.1@sha256:121a77066d8e306be37e9a7c6b5f3905281813e78811d0352e215e0d8c88b12c
    entrypoint: /bin/sh -c "[ -n \"${DISABLE}\" ] || exec /init"
    restart: on-failure
    environment:
      PUID: "1000"
      PGID: "1000"
    ports:
      - 127.0.0.1:5055:5055/tcp
    tmpfs:
      - /tmp
    volumes:
      - overseerr:/config

  # https://docs.linuxserver.io/images/docker-sabnzbd
  sabnzbd:
    image: linuxserver/sabnzbd:4.0.3
    entrypoint: /bin/sh -c "[ -n \"${DISABLE}\" ] || exec /init"
    restart: on-failure
    environment:
      PUID: "1000"
      PGID: "1000"
    ports:
      - 127.0.0.1:8080:8080/tcp
    tmpfs:
      - /tmp
    volumes:
      - sabnzbd:/config
      - downloads:/downloads

  # https://docs.linuxserver.io/images/docker-tautulli
  tautulli:
    image: linuxserver/tautulli:2021.12.16@sha256:9ba07aaddb8e2e7a6283eb8231dfd900f2d7dda38d70ec60fe7f5000a2dc0906
    entrypoint: /bin/sh -c "[ -n \"${DISABLE}\" ] || exec /init"
    restart: on-failure
    environment:
      PUID: "1000"
      PGID: "1000"
    ports:
      - 127.0.0.1:8181:8181/tcp
    tmpfs:
      - /tmp
    volumes:
      - tautulli:/config

    # https://hub.docker.com/r/netdata/netdata
  netdata:
    image: netdata/netdata:v1.41.0@sha256:2801d57b2050bc9071be8279d6f70a3ffe71a7881c84b524104080375ae0cb46
    privileged: true
    cap_add:
      - SYS_PTRACE
    environment:
      DOCKER_HOST: "/var/run/balena.sock"
      PGID: "990" # ls -nd /var/run/balena.sock | awk '{print $4}'
    labels:
      io.balena.features.balena-socket: 1
      io.balena.features.procfs: 1
      io.balena.features.supervisor-api: 1
      io.balena.features.sysfs: 1
    ports:
      - 127.0.0.1:19999:19999/tcp
    security_opt:
      - apparmor:unconfined
    tmpfs:
      - /tmp
    volumes:
      - netdatalib:/var/lib/netdata
      - netdatacache:/var/cache/netdata

  # https://docs.linuxserver.io/images/docker-duplicati
  duplicati:
    image: lscr.io/linuxserver/duplicati:v2.0.6.3-2.0.6.3_beta_2021-06-17-ls160@sha256:9cf7c7a14bf1474d44aa29d329552bf32af58090f4cfa5e61e35a88b2cd4677e
    entrypoint: /bin/sh -c "[ -n \"${DISABLE}\" ] || exec /init"
    restart: on-failure
    environment:
      PUID: "0"
      PGID: "0"
    ports:
      - 127.0.0.1:8200:8200/tcp
    tmpfs:
      - /tmp
    volumes:
      - duplicati:/config
      # any volumes that might be worth backing up
      - syncthing:/volumes/syncthing
      - plex:/volumes/plex
      - nzbget:/volumes/nzbget
      - sonarr:/volumes/sonarr
      - radarr:/volumes/radarr
      - nzbhydra:/volumes/nzbhydra
      - jellyfin:/volumes/jellyfin
      - prowlarr:/volumes/prowlarr
      - ombi:/volumes/ombi
      - overseerr:/volumes/overseerr
      - sabnzbd:/volumes/sabnzbd
      - tailscale:/volumes/tailscale
      - downloads:/volumes/downloads
      - proxy:/volumes/proxy
      - tautulli:/volumes/tautulli

  # https://docs.linuxserver.io/images/docker-syncthing
  syncthing:
    image: lscr.io/linuxserver/syncthing:1.23.6@sha256:58d5516868a30119e07c8f898b1ea51c85fe7cde4cfbab7c2b31becf4defbcdb
    entrypoint: /bin/sh -c "[ -n \"${DISABLE}\" ] || exec /init"
    restart: on-failure
    environment:
      PUID: "1000"
      PGID: "1000"
    ports:
      - 127.0.0.1:8384:8384/tcp
      - 22000:22000/tcp
      - 22000:22000/udp
      - 21027:21027/udp
    tmpfs:
      - /tmp
    volumes:
      - syncthing:/config
      # any volumes that might be worth syncronizing between machines
      - plex:/volumes/plex
      - nzbget:/volumes/nzbget
      - sonarr:/volumes/sonarr
      - radarr:/volumes/radarr
      - nzbhydra:/volumes/nzbhydra
      - jellyfin:/volumes/jellyfin
      - prowlarr:/volumes/prowlarr
      - ombi:/volumes/ombi
      - overseerr:/volumes/overseerr
      - sabnzbd:/volumes/sabnzbd
      - tailscale:/volumes/tailscale
      - downloads:/volumes/downloads
      - proxy:/volumes/proxy
      - tautulli:/volumes/tautulli

  # https://hub.docker.com/r/jc21/nginx-proxy-manager
  proxy:
    image: jc21/nginx-proxy-manager:2.10.3@sha256:e5407dfe0577301171f403ec6b8a01b87eca5420416a907f9c42775428e22fee
    ports:
      - 80:80/tcp
      - 127.0.0.1:81:81/tcp
      - 443:443/tcp
    tmpfs:
      - /tmp
    volumes:
      - proxy:/data
      - letsencrypt:/etc/letsencrypt

  # https://hub.docker.com/r/tailscale/tailscale
  tailscale:
    image: tailscale/tailscale:v1.44.0@sha256:a1a18e145f9dd0d67ede7ce88f2049eb5ae0c0706f1cea096147170410c2fb57
    network_mode: host
    cap_add:
      - NET_ADMIN
      - NET_RAW
      - SYS_MODULE
    labels:
      - io.balena.features.kernel-modules=1
    tmpfs:
      - /tmp
      - /var/run/
    volumes:
      - tailscale:/var/lib/tailscale
    environment:
      TS_STATE_DIR: "/var/lib/tailscale"
      TS_SOCKET: "/var/run/tailscale/tailscaled.sock"
      TS_EXTRA_ARGS: "--reset --accept-routes"
      TS_AUTH_ONCE: "true"
      # TS_USERSPACE: "true"
      # TS_ROUTES: 172.18.0.0/16
      TS_HOSTNAME: mediaserver
      # TS_DEST_IP: 127.0.0.1
    entrypoint:
      - /bin/sh
      - -c
    command:
      - |
        # load the kernel module if it exists
        if modprobe wireguard 2>/dev/null
        then
          modinfo wireguard || true
          export TS_USERSPACE="${TS_USERSPACE:-false}"
        fi

        mkdir -p /dev/net
        [ ! -c /dev/net/tun ] && mknod /dev/net/tun c 10 200
        
        /usr/local/bin/containerboot &
        pid=$!

        sleep 5

        tailscale serve reset
        
        tailscale serve tls-terminated-tcp:8200 tcp://127.0.0.1:8200
        # tailscale serve tls-terminated-tcp:8096 tcp://127.0.0.1:8096
        tailscale serve tls-terminated-tcp:19999 tcp://127.0.0.1:19999
        tailscale serve tls-terminated-tcp:6789 tcp://127.0.0.1:6789
        tailscale serve tls-terminated-tcp:5076 tcp://127.0.0.1:5076
        tailscale serve tls-terminated-tcp:3579 tcp://127.0.0.1:3579
        tailscale serve tls-terminated-tcp:5055 tcp://127.0.0.1:5055
        # tailscale serve tls-terminated-tcp:32400 tcp://127.0.0.1:32400
        tailscale serve tls-terminated-tcp:9696 tcp://127.0.0.1:9696
        tailscale serve tls-terminated-tcp:81 tcp://127.0.0.1:81
        tailscale serve tls-terminated-tcp:7878 tcp://127.0.0.1:7878
        tailscale serve tls-terminated-tcp:8989 tcp://127.0.0.1:8989
        tailscale serve tls-terminated-tcp:8080 tcp://127.0.0.1:8080
        tailscale serve tls-terminated-tcp:8181 tcp://127.0.0.1:8181
        tailscale serve tls-terminated-tcp:8384 tcp://127.0.0.1:8384

        tailscale serve status

        wait $pid
